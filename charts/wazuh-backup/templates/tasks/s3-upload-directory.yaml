# templates/tekton/tasks/s3-upload-directory.yaml
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: s3-upload-directory
  namespace: wazuh
  labels:
    app.kubernetes.io/name: s3-upload-directory
  annotations:
    tekton.dev/displayName: "Tarball + Upload to S3"
spec:
  description: |
    1. Archives a directory from the backup PVC into
       wazuh-manager-backup-<timestamp>.tar.gz
    2. Uploads that tarball to the requested S3 location.
  params:
    - name: sourceDirectoryPath
      type: string
      description: "Relative path under /backup to archive."
      default: "."          # treat /backup root if nothing given
    - name: s3BucketName
      type: string
      description: "Destination S3 bucket name."
    - name: s3ObjectKeyPrefix
      type: string
      description: "S3 key prefix (folder); leave blank for bucket root."
      default: ""
    - name: s3EndpointUrl
      type: string
      description: "Optional S3-compatible endpoint URL."
      default: ""
  steps:
    - name: make-tar
      image: "alpine:3.18"
      env:
        - name: SRC_SUBDIR
          value: "$(params.sourceDirectoryPath)"
      script: |
        set -euo pipefail

        SRC="/backup"
        if [ ! -d "${SRC}" ]; then
          echo "‚ùå Source directory ${SRC} does not exist."
          exit 1
        fi

        ts="$(date +'%Y%m%d')"
        ARCHIVE_NAME="wazuh-manager-backup-${ts}.tar.gz"
        ARCHIVE_PATH="/backup/${ARCHIVE_NAME}"

        echo "üì¶ Creating ${ARCHIVE_NAME} from ${SRC}/ ‚Ä¶"
        tar -czf "${ARCHIVE_PATH}" -C "${SRC}" .
        echo "‚úÖ Archive created at ${ARCHIVE_PATH}"
      volumeMounts:
        - name: backup-volume
          mountPath: /backup

    - name: s3-upload
      image: "{{ .Values.tekton.tasks.s3Upload.image }}"
      script: |
        #!/bin/sh
        set -euo pipefail

        # Pick the most-recent wazuh tarball left by the previous step
        ARCHIVE_PATH="$(ls -t /backup/wazuh-manager-backup-*.tar.gz | head -n1)"
        if [ ! -f "${ARCHIVE_PATH}" ]; then
          echo "‚ùå Expected archive not found in /backup/"
          exit 1
        fi

        DST_PREFIX="s3://${S3_BUCKET_NAME%/}"
        DST="${DST_PREFIX%/}/$(basename "${ARCHIVE_PATH}")"

        AWS_ARGS=""
        if [ -n "${S3_ENDPOINT_URL}" ]; then
          AWS_ARGS="--endpoint-url ${S3_ENDPOINT_URL}"
        fi

        echo "‚òÅÔ∏è  Uploading ${ARCHIVE_PATH} ‚Üí ${DST}"
        aws s3 cp ${AWS_ARGS} "${ARCHIVE_PATH}" "${DST}"
        echo "‚úÖ S3 upload complete."
      env:
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: "{{ .Values.aws.secretName }}"
              key: AWS_ACCESS_KEY_ID
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: "{{ .Values.aws.secretName }}"
              key: AWS_SECRET_ACCESS_KEY
        - name: AWS_SESSION_TOKEN
          valueFrom:
            secretKeyRef:
              name: "{{ .Values.aws.secretName }}"
              key: AWS_SESSION_TOKEN
        - name: AWS_DEFAULT_REGION
          value: "{{ .Values.aws.region }}"
        - name: S3_BUCKET_NAME
          value: "$(params.s3BucketName)"
        - name: S3_OBJECT_KEY_PREFIX
          value: "$(params.s3ObjectKeyPrefix)"
        - name: S3_ENDPOINT_URL
          value: "$(params.s3EndpointUrl)"
      volumeMounts:
        - name: backup-volume
          mountPath: /backup

  # Shared PVC providing /backup for both steps
  volumes:
    - name: backup-volume
      persistentVolumeClaim:
        claimName: backup-staging-pvc
